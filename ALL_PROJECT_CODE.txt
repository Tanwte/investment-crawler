# INVESTMENT CRAWLER - COMPLETE CODE DOCUMENTATION
# Generated on September 19, 2025
# Repository: webCrawler (Owner: Twtedwin)

==============================================================================
ALL PROJECT FILES WITH COMPLETE CODE
==============================================================================

################################################################################
ROOT DIRECTORY FILES
################################################################################

================================================================================
.env
================================================================================
DATABASE_URL=postgresql://neondb_owner:npg_RbNwkej0HLs8@ep-super-mountain-a1kl5p20-pooler.ap-southeast-1.aws.neon.tech/neondb?sslmode=require
PORT=3000
HTTPS_PORT=3001
SESSION_SECRET=change_this_long_random_string
CRAWL_TOKEN=longrandomstring
NODE_ENV=development

================================================================================
.gitignore
================================================================================
# Dependencies
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Runtime data
pids
*.pid
*.seed
*.pid.lock

# Coverage directory used by tools like istanbul
coverage/

# nyc test coverage
.nyc_output

# Environment variables
.env
.env.local
.env.development.local
.env.test.local
.env.production.local

# Logs
logs
*.log

# Optional npm cache directory
.npm

# Optional REPL history
.node_repl_history

# Output of 'npm pack'
*.tgz

# Yarn Integrity file
.yarn-integrity

# dotenv environment variables file
.env

# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Editor directories and files
.vscode/
.idea/
*.swp
*.swo

# Temporary files
*.tmp
.tmp/

# Temporary test and debug files
test-*.js
debug-*.js
demo-*.js
check-*.js
quick-test.js

# Allow working demos
!visited-urls-demo.js

# Temporary migration files
migrations.sql

================================================================================
config.js
================================================================================
module.exports = {
  concurrency: 5,
  userAgent: 'investment-crawler/1.0 (+https://example.org/contact)',
  requestTimeoutMs: 15000,
  pageTimeoutMs: 30000,
  contextChars: 240,
  crawlDelayMsPerHost: 1500,
  csp: {
    "default-src": ["'self'"],
    "script-src": ["'self' 'unsafe-inline'"],
    "script-src-attr": ["'unsafe-inline'"],
    "style-src": ["'self' 'unsafe-inline'"],
    "img-src": ["'self' data:"],
    "connect-src": ["'self'"],
    "frame-ancestors": ["'none'"]
  }
};

================================================================================
server.js
================================================================================
// server.js
require('dotenv').config();
const path = require('path');
const express = require('express');
const session = require('express-session');
const https = require('https');
const fs = require('fs');

const { applySecurity } = require('./middleware/security');
const { initAuth } = require('./db/initAuth');

const authRouter = require('./routes/auth');
const crawlRouter = require('./routes/crawl');
const searchRouter = require('./routes/search');
const adminRouter = require('./routes/admin');
const dashboardRouter = require('./routes/dashboard');

const app = express();
applySecurity(app);

// Body parsing and cookies
app.use(express.json());
app.use(express.urlencoded({ extended: true }));
app.use(require('cookie-parser')());

// Views + static
app.set('view engine', 'ejs');
app.set('views', path.join(__dirname, 'views'));
app.use(express.static(path.join(__dirname, 'public'), { maxAge: '1h' }));

// Health (public)
app.get('/healthz', (req, res) => res.send('ok'));

// Sessions
const prod = process.env.NODE_ENV === 'production';
app.use(session({
  secret: process.env.SESSION_SECRET || 'dev-secret',
  resave: false,
  saveUninitialized: false,
  rolling: true, // Reset expiration on activity
  cookie: { 
    httpOnly: true, 
    sameSite: 'lax', 
    secure: prod,
    maxAge: 24 * 60 * 60 * 1000 // 24 hours, extended for admin work
  }
}));

// Routes
app.use('/', authRouter);
app.use('/', crawlRouter);
app.use('/', searchRouter);
app.use('/', adminRouter);
app.use('/', dashboardRouter);

// Default route
app.get('/', (req, res) => res.redirect('/login'));

const port = process.env.PORT || 3000;

// In tests, we export app without listening.
if (process.env.NODE_ENV !== 'test') {
  initAuth().then(() => {
    // Start HTTP server
    app.listen(port, () => console.log(`HTTP Server on :${port}`));
    
    // Start HTTPS server if SSL certificates exist
    const keyPath = path.join(__dirname, 'ssl', 'localhost-key.pem');
    const certPath = path.join(__dirname, 'ssl', 'localhost-cert.pem');
    
    if (fs.existsSync(keyPath) && fs.existsSync(certPath)) {
      const httpsPort = process.env.HTTPS_PORT || 3443;
      const httpsOptions = {
        key: fs.readFileSync(keyPath),
        cert: fs.readFileSync(certPath)
      };
      
      https.createServer(httpsOptions, app).listen(httpsPort, () => {
        console.log(`HTTPS Server on :${httpsPort}`);
        console.log(`üîí Access via: https://localhost:${httpsPort}`);
        console.log(`‚ö†Ô∏è  Browser will show security warning - click "Advanced" ‚Üí "Proceed to localhost"`);
      });
    } else {
      console.log('‚ÑπÔ∏è  HTTPS not available - SSL certificates not found');
      console.log('   Run: node scripts/generate-ssl.js to create certificates');
    }
  }).catch(err => {
    console.error('Init failed:', err);
    process.exit(1);
  });
} else {
  // In tests, ensure seed users exist before exporting.
  initAuth().catch(err => {
    console.error('Init (test) failed:', err);
  });
}

module.exports = app;

================================================================================
visited-urls-demo.js
================================================================================
const DeepLinkCrawler = require('./utils/deepLinkCrawler');

async function testVisitedUrls() {
  try {
    console.log('üîç Testing visited URL tracking...');
    
    const keywords = ['Singapore', 'Lee Kuan Yew'];
    const deepCrawler = new DeepLinkCrawler({
      maxDepth: 2,
      maxLinksPerPage: 3, // Small number for testing
      crawlDelay: 500
    });
    
    console.log('\nüöÄ Starting crawl from ASEAN page...');
    const result = await deepCrawler.crawlWithDeepLinks('https://en.wikipedia.org/wiki/ASEAN', keywords, 0);
    
    console.log('\nüìä Final Crawl Statistics:');
    const stats = deepCrawler.getStats();
    console.log(`   Total URLs visited: ${stats.visitedUrls}`);
    console.log(`   Unique domains: ${stats.visitedDetails.uniqueDomains}`);
    console.log(`   Domains crawled: ${stats.visitedDetails.domains.join(', ')}`);
    
    console.log('\nüåê URLs Visited:');
    stats.visitedDetails.recentUrls.forEach((url, i) => {
      console.log(`   ${i+1}. ${url}`);
    });
    
    console.log('\nüîÑ Testing duplicate detection...');
    console.log('Attempting to crawl ASEAN page again (should be skipped):');
    
    const duplicateResult = await deepCrawler.crawlWithDeepLinks('https://en.wikipedia.org/wiki/ASEAN', keywords, 0);
    
    console.log(`\nüìà Results:`);
    console.log(`   First crawl: ${result.results.length} pages`);
    console.log(`   Duplicate crawl: ${duplicateResult.results.length} pages (should be 0)`);
    
    if (duplicateResult.results.length === 0) {
      console.log('‚úÖ SUCCESS: Duplicate URL detection working correctly!');
    } else {
      console.log('‚ùå FAILED: Duplicate URLs were not detected');
    }
    
    console.log('\nüîç Full visited URL list:');
    const allVisited = deepCrawler.getVisitedUrls();
    allVisited.forEach((url, i) => {
      console.log(`   ${i+1}. ${url}`);
    });
    
  } catch (error) {
    console.error('‚ùå Test failed:', error.message);
  }
}

testVisitedUrls();


================================================================================
package.json
================================================================================
{
  "name": "investment-crawler",
  "version": "1.0.0",
  "description": "",
  "main": "index.js",
  "scripts": {
    "start": "node server.js",
    "dev": "nodemon server.js",
    "test": "jest --runInBand --detectOpenHandles"
  },
  "nodemonConfig": {
    "ignore": [
      "data/*",
      "*.log",
      "node_modules/*"
    ],
    "ext": "js,json,ejs"
  },
  "jest": {
    "testEnvironment": "node",
    "setupFilesAfterEnv": [
      "<rootDir>/tests/testSetup.js"
    ],
    "moduleNameMapper": {
      "^../db$": "<rootDir>/tests/mocks/db.js",
      "^./index$": "<rootDir>/tests/mocks/db.js",
      "^axios$": "<rootDir>/tests/mocks/axios.js",
      "^axios-retry$": "<rootDir>/tests/mocks/axios-retry.js",
      "^puppeteer$": "<rootDir>/tests/mocks/puppeteer.js",
      "^p-limit$": "<rootDir>/tests/mocks/p-limit.js",
      "^robots-parser$": "<rootDir>/tests/mocks/robots-parser.js",
      "^sanitize-html$": "<rootDir>/tests/mocks/sanitize-html.js",
      "^csurf$": "<rootDir>/tests/mocks/csurf.js"
    }
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "type": "commonjs",
  "dependencies": {
    "axios": "^1.12.2",
    "axios-retry": "^3.9.1",
    "bcrypt": "^6.0.0",
    "cheerio": "^1.1.2",
    "compression": "^1.8.1",
    "cookie-parser": "^1.4.7",
    "cors": "^2.8.5",
    "csurf": "^1.11.0",
    "dotenv": "^17.2.2",
    "ejs": "^3.1.10",
    "express": "^5.1.0",
    "express-rate-limit": "^8.1.0",
    "express-session": "^1.18.2",
    "express-validator": "^7.2.1",
    "helmet": "^8.1.0",
    "p-limit": "^3.1.0",
    "pg": "^8.16.3",
    "pino": "^9.10.0",
    "puppeteer": "^24.22.0",
    "puppeteer-extra": "^3.3.6",
    "puppeteer-extra-plugin-stealth": "^2.11.2",
    "robots-parser": "^3.0.1",
    "sanitize-html": "^2.17.0",
    "selfsigned": "^3.0.1",
    "user-agents": "^1.1.662"
  },
  "devDependencies": {
    "jest": "^29.7.0",
    "nodemon": "^3.1.10",
    "supertest": "^6.3.4"
  }
}